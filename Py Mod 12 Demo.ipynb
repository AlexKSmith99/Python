{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "890d4c22",
   "metadata": {},
   "source": [
    "### Machine Learning - Brief Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960258d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One word: demystification\n",
    "# Not on the assessment/necessary for most Data Analyst job interviews/jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28028a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do imports and examine the data\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "pima = pd.read_csv((\"https://raw.githubusercontent.com/PyDataWorkshop/datasets/master/pima.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "269870ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preg</th>\n",
       "      <th>Gluc</th>\n",
       "      <th>Dias</th>\n",
       "      <th>Tric</th>\n",
       "      <th>2hSer</th>\n",
       "      <th>BM1</th>\n",
       "      <th>Diab</th>\n",
       "      <th>Age</th>\n",
       "      <th>Diab.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Preg   Gluc  Dias  Tric  2hSer   BM1   Diab  Age  Diab.1\n",
       "0      6   148    72    35      0  33.6  0.627   50       1\n",
       "1      1    85    66    29      0  26.6  0.351   31       0\n",
       "2      8   183    64     0      0  23.3  0.672   32       1\n",
       "3      1    89    66    23     94  28.1  0.167   21       0\n",
       "4      0   137    40    35    168  43.1  2.288   33       1"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ca260e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   Preg    768 non-null    int64  \n",
      " 1   Gluc    768 non-null    int64  \n",
      " 2   Dias    768 non-null    int64  \n",
      " 3   Tric    768 non-null    int64  \n",
      " 4   2hSer   768 non-null    int64  \n",
      " 5   BM1     768 non-null    float64\n",
      " 6   Diab    768 non-null    float64\n",
      " 7   Age     768 non-null    int64  \n",
      " 8   Diab.1  768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "pima.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cf48ab",
   "metadata": {},
   "source": [
    "<strong>Diab</strong> = Likelihood of patient diabetes based on family history<br>\n",
    "<strong>Diab.1</strong> = Whether patient has diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9eba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with a very basic linear regression\n",
    "# The simplest form of predictive analytics - can even be done in Excel\n",
    "# Set up linear regression\n",
    "# Initialize an empty linear regression variable\n",
    "reg = LinearRegression()\n",
    "reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "33540162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(614, 9)\n",
      "(154, 9)\n",
      "0.8094059405940595\n"
     ]
    }
   ],
   "source": [
    "# Train test split with 80% of the data used for training, 20% for testing (sometimes hold-out data)\n",
    "# Why? Because we would not want to evaluate accuracy based on biased data\n",
    "# If we give 100% of data, it will have already learned all of that data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(pima, test_size = 0.2)\n",
    "# \"Test\" is also the hold-out because it is removed and then\n",
    "# accuracy is measured based on that\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "# 80% of ROWS are in train\n",
    "# 20% of ROWS are in test\n",
    "# Columns are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3c1127b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Preg</th>\n",
       "      <th>Gluc</th>\n",
       "      <th>Dias</th>\n",
       "      <th>Tric</th>\n",
       "      <th>2hSer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>56</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1</td>\n",
       "      <td>117</td>\n",
       "      <td>88</td>\n",
       "      <td>24</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>64</td>\n",
       "      <td>14</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>0</td>\n",
       "      <td>161</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "      <td>64</td>\n",
       "      <td>30</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>72</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>7</td>\n",
       "      <td>133</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>614 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Preg   Gluc  Dias  Tric  2hSer\n",
       "585      1    93    56    11      0\n",
       "128      1   117    88    24    145\n",
       "392      1   131    64    14    415\n",
       "108      3    83    58    31     18\n",
       "109      0    95    85    25     36\n",
       "..     ...   ...   ...   ...    ...\n",
       "103      1    81    72    18     40\n",
       "294      0   161    50     0      0\n",
       "427      1   181    64    30    180\n",
       "501      3    84    72    32      0\n",
       "41       7   133    84     0      0\n",
       "\n",
       "[614 rows x 5 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick the non-Diab columns as feature variables (predictors)\n",
    "train_feat = train.iloc[:,:5]\n",
    "# iloc reminder: rows first, then columns\n",
    "# train_feat = np.array(train.iloc[:,1]).reshape(-1, 1)\n",
    "# Pick the Diab column as a target variable (response)\n",
    "train_targ = train[\"Diab\"]\n",
    "train_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8d1a7371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585    0.417\n",
       "128    0.403\n",
       "392    0.389\n",
       "108    0.336\n",
       "109    0.247\n",
       "       ...  \n",
       "103    0.283\n",
       "294    0.254\n",
       "427    0.328\n",
       "501    0.267\n",
       "41     0.696\n",
       "Name: Diab, Length: 614, dtype: float64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8cff05ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "# Tell Python what we want to predict\n",
    "# Order is predictor, target\n",
    "reg.fit(train_feat, train_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "73a57909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Preg   Gluc  Dias  Tric  2hSer\n",
      "562      1    87    68    34     77\n",
      "460      9   120    72    22     56\n",
      "483      0    84    82    31    125\n",
      "450      1    82    64    13     95\n",
      "240      1    91    64    24      0\n",
      "..     ...   ...   ...   ...    ...\n",
      "442      4   117    64    27    120\n",
      "146      9    57    80    37      0\n",
      "257      2   114    68    22      0\n",
      "322      0   124    70    20      0\n",
      "259     11   155    76    28    150\n",
      "\n",
      "[154 rows x 5 columns]\n",
      "562    0.401\n",
      "460    0.733\n",
      "483    0.233\n",
      "450    0.415\n",
      "240    0.192\n",
      "       ...  \n",
      "442    0.230\n",
      "146    0.096\n",
      "257    0.092\n",
      "322    0.254\n",
      "259    1.353\n",
      "Name: Diab, Length: 154, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Test variables\n",
    "test_feat = test.iloc[:,:5]\n",
    "# test_feat = np.array(test.iloc[:,1]).reshape(-1, 1)\n",
    "test_targ = test[\"Diab\"]\n",
    "print(test_feat)\n",
    "print(test_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "06cf5b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  \n",
      " [0.4933748  0.45630597 0.49187907 0.43442806 0.45078751] \n",
      "Actual: \n",
      " 562    0.401\n",
      "460    0.733\n",
      "483    0.233\n",
      "450    0.415\n",
      "240    0.192\n",
      "Name: Diab, dtype: float64 \n",
      " Slope:  [-0.00260826  0.00074559 -0.00031292  0.00288871  0.00023291] Intercept:  0.33624457186212425\n"
     ]
    }
   ],
   "source": [
    "# Predict the age of patients for the first five values\n",
    "print(\"Predictions: \", \"\\n\", reg.predict(test_feat)[0:5,], \"\\nActual: \\n\",\\\n",
    "      test_targ[0:5,], \"\\n\", \"Slope: \", reg.coef_, \"Intercept: \", reg.intercept_)\n",
    "# How does this work? Each feature variable is multiplied by the slope and added to the intercept\n",
    "# For example, if for every horsepower a car is $100 more, multiply $100 times each mpg obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.predict(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "60365b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared: 0.08236603616885263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"R squared:\", r2_score(test_targ.values, reg.predict(test_feat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c037999",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bd40b24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up logistic regression\n",
    "# Logistic regression predicts the ODDS, rather than the OUTCOME - see the binary column above\n",
    "# If its prediction is 0.5 or greater, predict patient has diabetes; if 0.49 or less, predict they do not\n",
    "# Import from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize an empty logistic regression variable\n",
    "lr = LogisticRegression()\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "66038f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split with 80% of the data used for training, 20% for testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(pima, test_size = 0.2)\n",
    "# Subset all the columns besides Diab.1\n",
    "train_feat = train.iloc[:,:8]\n",
    "# Subset just the Diab.1 column\n",
    "train_targ = train[\"Diab.1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8b0ced99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melgoss/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Populate our null variable with predictions\n",
    "lr.fit(train_feat, train_targ)\n",
    "# Subset all the columns in Test besides Diab.1\n",
    "test_feat = test.iloc[:,:8]\n",
    "# Subset just the Diab.1 column\n",
    "test_targ = test['Diab.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "55b981e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7402597402597403"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See how accurate the model is\n",
    "lr.score(test_feat, test_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3ca753b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need more details\n",
    "# Let's look at our predictions\n",
    "lr.predict(test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f845208c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[85, 27],\n",
       "       [13, 29]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rather than comparing every prediction to every actual, we can create what's called a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(lr.predict(test_feat), test_targ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5919cd",
   "metadata": {},
   "source": [
    "We have two potential correct outcomes, as well as two potential incorrect outcomes. Our incorrect outcomes can take the following forms:\n",
    "\n",
    "Our model made a positive prediction, and it was wrong. (False Positive)\n",
    "\n",
    "Our model made a negative prediction, and it was wrong. (False Negative)\n",
    "\n",
    "Percentage of true positives = TP / (TP + FP) aka <strong>precision</strong><br>\n",
    "Percentage of true negatives = TN / (TN + FN) aka <strong>recall</strong>\n",
    "\n",
    "While the overall accuracy is also a useful metric, the difference between these concepts in a business context can have large ramifications, making simple accuracy often not enough for a robust model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb3bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn <=> Confusion Matrix\n",
    "\"\"\"labels = [‘True Neg’,’False Pos’,’False Neg’,’True Pos’]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt=‘’, cmap='Blues')\n",
    "group_names = [‘True Neg’,’False Pos’,’False Neg’,’True Pos’]\n",
    "group_counts = [“{0:0.0f}”.format(value) for value in\n",
    "cf_matrix.flatten()]\n",
    "group_percentages = [“{0:.2%}”.format(value) for value in\n",
    "cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "labels = [f”{v1}\\n{v2}\\n{v3}” for v1, v2, v3 in\n",
    "zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cf_matrix, annot=labels, fmt=‘’, cmap='Blues')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f2a75e37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5178571428571429\n",
      "Recall: 0.6904761904761905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(\"Precision:\", precision_score(lr.predict(test_feat), test_targ))\n",
    "print(\"Recall:\", recall_score(lr.predict(test_feat), test_targ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe7dc4",
   "metadata": {},
   "source": [
    "### Different Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d393c9db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melgoss/opt/anaconda3/lib/python3.9/site-packages/sklearn/svm/_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy 0.6363636363636364\n",
      "Neural net accuracy 0.7662337662337663\n",
      "Random forest 0.935064935064935\n"
     ]
    }
   ],
   "source": [
    "# Import three new models\n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.neural_network import MLPClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Initialize the models\n",
    "svm = LinearSVC()\n",
    "mlp = MLPClassifier()\n",
    "rf = RandomForestClassifier()\n",
    "# Train test split\n",
    "train, test = train_test_split(pima, test_size=.2)  \n",
    "train_feat = train.iloc[:, :8]\n",
    "train_targ = train[\"Diab.1\"]\n",
    "# Fit the models\n",
    "svm.fit(train_feat, train_targ)\n",
    "mlp.fit(train_feat, train_targ)\n",
    "rf.fit(train_feat, train_targ)\n",
    "# Examine the scores\n",
    "print(\"SVM accuracy\", svm.score(test_feat, test_targ))\n",
    "print(\"Neural net accuracy\", mlp.score(test_feat, test_targ))\n",
    "print(\"Random forest\", rf.score(test_feat, test_targ))\n",
    "# Bootstrapping allows you to test multiple accuracies\n",
    "# Then average them out to find total accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2effb164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98, 56],\n",
       "       [ 0,  0]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrices\n",
    "confusion_matrix(svm.predict(test_feat), test_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "272a37dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90, 28],\n",
       "       [ 8, 28]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(mlp.predict(test_feat),test_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7989e3e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94,  6],\n",
       "       [ 4, 50]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(rf.predict(test_feat),test_targ)\n",
    "# Random forest is by far the most successful; go with that one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
